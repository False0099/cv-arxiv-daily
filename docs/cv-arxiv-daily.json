{"Processing-in-Memory": {"2512.15716": "|**2025-12-17**|**Spatia: Video Generation with Updatable Spatial Memory**|Jinjing Zhao et.al.|[2512.15716](http://arxiv.org/abs/2512.15716)|null|\n", "2512.15705": "|**2025-12-17**|**Dynamic Rebatching for Efficient Early-Exit Inference with DREX**|Xuting Liu et.al.|[2512.15705](http://arxiv.org/abs/2512.15705)|null|\n", "2512.15679": "|**2025-12-17**|**A High-level Synthesis Toolchain for the Julia Language**|Benedict Short et.al.|[2512.15679](http://arxiv.org/abs/2512.15679)|null|\n", "2512.15653": "|**2025-12-17**|**Characterizing Mamba's Selective Memory using Auto-Encoders**|Tamanna Hossain et.al.|[2512.15653](http://arxiv.org/abs/2512.15653)|null|\n", "2512.15479": "|**2025-12-17**|**Correlations between rare events due to long-term memory**|Apurba Biswas et.al.|[2512.15479](http://arxiv.org/abs/2512.15479)|null|\n", "2512.15231": "|**2025-12-17**|**CangLing-KnowFlow: A Unified Knowledge-and-Flow-fused Agent for Comprehensive Remote Sensing Applications**|Zhengchao Chen et.al.|[2512.15231](http://arxiv.org/abs/2512.15231)|null|\n", "2512.15186": "|**2025-12-17**|**ERIENet: An Efficient RAW Image Enhancement Network under Low-Light Environment**|Jianan Wang et.al.|[2512.15186](http://arxiv.org/abs/2512.15186)|null|\n", "2512.14865": "|**2025-12-16**|**Audio MultiChallenge: A Multi-Turn Evaluation of Spoken Dialogue Systems on Natural Human Interaction**|Advait Gosai et.al.|[2512.14865](http://arxiv.org/abs/2512.14865)|null|\n", "2512.14585": "|**2025-12-16**|**Towards Nepali-language LLMs: Efficient GPT training with a Nepali BPE tokenizer**|Adarsha Shrestha et.al.|[2512.14585](http://arxiv.org/abs/2512.14585)|null|\n", "2512.14531": "|**2025-12-16**|**VersatileFFN: Achieving Parameter Efficiency in LLMs via Adaptive Wide-and-Deep Reuse**|Ying Nie et.al.|[2512.14531](http://arxiv.org/abs/2512.14531)|null|\n", "2512.16824": "|**2025-12-18**|**Tiny Recursive Control: Iterative Reasoning for Efficient Optimal Control**|Amit Jain et.al.|[2512.16824](http://arxiv.org/abs/2512.16824)|null|\n", "2512.16822": "|**2025-12-18**|**MEPIC: Memory Efficient Position Independent Caching for LLM Serving**|Qian Wang et.al.|[2512.16822](http://arxiv.org/abs/2512.16822)|null|\n", "2512.16684": "|**2025-12-18**|**Lower bounds for ranking-based pivot rules**|Yann Disser et.al.|[2512.16684](http://arxiv.org/abs/2512.16684)|null|\n", "2512.16531": "|**2025-12-18**|**Scaling Laws for Energy Efficiency of Local LLMs**|Ander Alvarez et.al.|[2512.16531](http://arxiv.org/abs/2512.16531)|null|\n", "2512.16311": "|**2025-12-18**|**Bunch-by-Bunch Prediction of Beam Transverse Position, Phase, and Length in a Storage Ring Using Neural Networks**|Can Liu et.al.|[2512.16311](http://arxiv.org/abs/2512.16311)|null|\n", "2512.16179": "|**2025-12-18**|**Local Lyapunov Analysis via Micro-Ensembles: finite-time Lyapunov exponent Estimation and KNN-Based Predictive Comparison in Complex-Valued BAM Neural Networks**|Yazhini Muruganantham et.al.|[2512.16179](http://arxiv.org/abs/2512.16179)|null|\n", "2512.16148": "|**2025-12-18**|**FlexKV: Flexible Index Offloading for Memory-Disaggregated Key-Value Store**|Zhisheng Hu et.al.|[2512.16148](http://arxiv.org/abs/2512.16148)|null|\n", "2512.16136": "|**2025-12-18**|**Lotus: Optimizing Disaggregated Transactions with Disaggregated Locks**|Zhisheng Hu et.al.|[2512.16136](http://arxiv.org/abs/2512.16136)|null|\n", "2512.15988": "|**2025-12-17**|**Vertical NAND in a Ferroelectric-driven Paradigm Shift**|Giuk Kim et.al.|[2512.15988](http://arxiv.org/abs/2512.15988)|null|\n", "2512.15891": "|**2025-12-17**|**Dynamical Mechanisms for Coordinating Long-term Working Memory Based on the Precision of Spike-timing in Cortical Neurons**|Terrence J. Sejnowski et.al.|[2512.15891](http://arxiv.org/abs/2512.15891)|null|\n", "2512.21333": "|**2025-12-24**|**Fast SAM2 with Text-Driven Token Pruning**|Avilasha Mandal et.al.|[2512.21333](http://arxiv.org/abs/2512.21333)|null|\n", "2512.21280": "|**2025-12-24**|**SMART SLM: Structured Memory and Reasoning Transformer, A Small Language Model for Accurate Document Assistance**|Divij Dudeja et.al.|[2512.21280](http://arxiv.org/abs/2512.21280)|null|\n", "2512.21220": "|**2025-12-24**|**RoboSafe: Safeguarding Embodied Agents via Executable Safety Logic**|Le Wang et.al.|[2512.21220](http://arxiv.org/abs/2512.21220)|null|\n", "2512.21153": "|**2025-12-24**|**ElfCore: A 28nm Neural Processor Enabling Dynamic Structured Sparse Training and Online Self-Supervised Learning with Activity-Dependent Weight Update**|Zhe Su et.al.|[2512.21153](http://arxiv.org/abs/2512.21153)|null|\n", "2512.21002": "|**2025-12-24**|**Distilling the Essence: Efficient Reasoning Distillation via Sequence Truncation**|Wei-Rui Chen et.al.|[2512.21002](http://arxiv.org/abs/2512.21002)|null|\n", "2512.21000": "|**2025-12-24**|**CoSeNet: A Novel Approach for Optimal Segmentation of Correlation Matrices**|Alberto. Palomo-Alonso et.al.|[2512.21000](http://arxiv.org/abs/2512.21000)|null|\n", "2512.20997": "|**2025-12-24**|**LLM-Empowered Agentic AI for QoE-Aware Network Slicing Management in Industrial IoT**|Xudong Wang et.al.|[2512.20997](http://arxiv.org/abs/2512.20997)|null|\n", "2512.20954": "|**2025-12-24**|**Reflection Pretraining Enables Token-Level Self-Correction in Biological Sequence Models**|Xiang Zhang et.al.|[2512.20954](http://arxiv.org/abs/2512.20954)|null|\n", "2512.20808": "|**2025-12-23**|**Hardware-Algorithm Co-Design for Hyperdimensional Computing Based on Memristive System-on-Chip**|Yi Huang et.al.|[2512.20808](http://arxiv.org/abs/2512.20808)|null|\n", "2512.20724": "|**2025-12-23**|**SA-DiffuSeq: Addressing Computational and Scalability Challenges in Long-Document Generation with Sparse Attention**|Alexandros Christoforos et.al.|[2512.20724](http://arxiv.org/abs/2512.20724)|null|\n", "2512.23212": "|**2025-12-29**|**LIMO: Low-Power In-Memory-Annealer and Matrix-Multiplication Primitive for Edge Computing**|Amod Holla et.al.|[2512.23212](http://arxiv.org/abs/2512.23212)|null|\n", "2512.23145": "|**2025-12-29**|**Reservoir Computing inspired Matrix Multiplication-free Language Model**|Takumi Shiratsuchi et.al.|[2512.23145](http://arxiv.org/abs/2512.23145)|null|\n", "2512.22995": "|**2025-12-28**|**Evolution of Buffer Management in Database Systems: From Classical Algorithms to Machine Learning and Disaggregated Memory**|Prudhvi Gadupudi et.al.|[2512.22995](http://arxiv.org/abs/2512.22995)|null|\n", "2512.22722": "|**2025-12-27**|**Protonic Nickelate Device Networks for Spatiotemporal Neuromorphic Computing**|Yue Zhou et.al.|[2512.22722](http://arxiv.org/abs/2512.22722)|null|\n", "2512.22716": "|**2025-12-27**|**Memento-II: Learning by Stateful Reflective Memory**|Jun Wang et.al.|[2512.22716](http://arxiv.org/abs/2512.22716)|null|\n", "2512.22676": "|**2025-12-27**|**Synthesis of signal processing algorithms with constraints on minimal parallelism and memory space**|Sergey Salishev et.al.|[2512.22676](http://arxiv.org/abs/2512.22676)|null|\n", "2512.22536": "|**2025-12-27**|**CoAgent: Collaborative Planning and Consistency Agent for Coherent Video Generation**|Qinglin Zeng et.al.|[2512.22536](http://arxiv.org/abs/2512.22536)|null|\n", "2512.22435": "|**2025-12-27**|**AnalogSAGE: Self-evolving Analog Design Multi-Agents with Stratified Memory and Grounded Experience**|Zining Wang et.al.|[2512.22435](http://arxiv.org/abs/2512.22435)|null|\n", "2512.22388": "|**2025-12-26**|**BLISS: Bandit Layer Importance Sampling Strategy for Efficient Training of Graph Neural Networks**|Omar Alsaqa et.al.|[2512.22388](http://arxiv.org/abs/2512.22388)|null|\n", "2512.22087": "|**2025-12-26**|**Context as a Tool: Context Management for Long-Horizon SWE-Agents**|Shukai Liu et.al.|[2512.22087](http://arxiv.org/abs/2512.22087)|null|\n"}, "Hybrid PIM Architectures": {"2511.06770": "|**2025-11-10**|**ASTER: Attention-based Spiking Transformer Engine for Event-driven Reasoning**|Tamoghno Das et.al.|[2511.06770](http://arxiv.org/abs/2511.06770)|null|\n", "2510.19260": "|**2025-10-22**|**Res-DPU: Resource-shared Digital Processing-in-memory Unit for Edge-AI Workloads**|Mukul Lokhande et.al.|[2510.19260](http://arxiv.org/abs/2510.19260)|null|\n", "2509.22980": "|**2025-09-30**|**No One-Size-Fits-All: A Workload-Driven Characterization of Bit-Parallel vs. Bit-Serial Data Layouts for Processing-using-Memory**|Jingyao Zhang et.al.|[2509.22980](http://arxiv.org/abs/2509.22980)|null|\n", "2509.13710": "|**2025-09-17**|**CompAir: Synergizing Complementary PIMs and In-Transit NoC Computation for Efficient LLM Acceleration**|Hongyi Li et.al.|[2509.13710](http://arxiv.org/abs/2509.13710)|null|\n", "2506.00020": "|**2025-05-20**|**Hybrid SLC-MLC RRAM Mixed-Signal Processing-in-Memory Architecture for Transformer Acceleration via Gradient Redistribution**|Chang Eun Song et.al.|[2506.00020](http://arxiv.org/abs/2506.00020)|null|\n", "2504.01468": "|**2025-04-02**|**HH-PIM: Dynamic Optimization of Power and Performance with Heterogeneous-Hybrid PIM for Edge AI Devices**|Sangmin Jeon et.al.|[2504.01468](http://arxiv.org/abs/2504.01468)|null|\n", "2504.01994": "|**2025-03-31**|**PIM-LLM: A High-Throughput Hybrid PIM Architecture for 1-bit LLMs**|Jinendra Malekar et.al.|[2504.01994](http://arxiv.org/abs/2504.01994)|null|\n", "2502.15470": "|**2025-02-27**|**PAPI: Exploiting Dynamic Parallelism in Large Language Model Decoding with a Processing-In-Memory-Enabled Computing System**|Yintao He et.al.|[2502.15470](http://arxiv.org/abs/2502.15470)|null|\n", "2404.04708": "|**2024-04-06**|**Efficient Sparse Processing-in-Memory Architecture (ESPIM) for Machine Learning Inference**|Mingxuan He et.al.|[2404.04708](http://arxiv.org/abs/2404.04708)|null|\n", "2310.12182": "|**2023-10-27**|**Block-Wise Mixed-Precision Quantization: Enabling High Efficiency for Practical ReRAM-based DNN Accelerators**|Xueying Wu et.al.|[2310.12182](http://arxiv.org/abs/2310.12182)|null|\n"}, "Memory-Centric Architectures": {"2510.11192": "|**2025-10-13**|**Efficient In-Memory Acceleration of Sparse Block Diagonal LLMs**|Jo\u00e3o Paulo Cardoso de Lima et.al.|[2510.11192](http://arxiv.org/abs/2510.11192)|null|\n", "2509.22986": "|**2025-09-26**|**CryptoSRAM: Enabling High-Throughput Cryptography on MCUs via In-SRAM Computing**|Jingyao Zhang et.al.|[2509.22986](http://arxiv.org/abs/2509.22986)|null|\n", "2505.00458": "|**2025-09-04**|**Memory-Centric Computing: Solving Computing's Memory Problem**|Onur Mutlu et.al.|[2505.00458](http://arxiv.org/abs/2505.00458)|null|\n", "2504.19413": "|**2025-04-28**|**Mem0: Building Production-Ready AI Agents with Scalable Long-Term Memory**|Prateek Chhikara et.al.|[2504.19413](http://arxiv.org/abs/2504.19413)|null|\n", "2504.09775": "|**2025-11-25**|**Understanding and Optimizing Multi-Stage AI Inference Pipelines**|Abhimanyu Rajeshkumar Bambhaniya et.al.|[2504.09775](http://arxiv.org/abs/2504.09775)|null|\n", "2412.20249": "|**2025-02-20**|**Next-Gen Computing Systems with Compute Express Link: a Comprehensive Survey**|Chen Chen et.al.|[2412.20249](http://arxiv.org/abs/2412.20249)|null|\n", "2412.19275": "|**2024-12-26**|**Memory-Centric Computing: Recent Advances in Processing-in-DRAM**|Onur Mutlu et.al.|[2412.19275](http://arxiv.org/abs/2412.19275)|null|\n", "2409.16777": "|**2024-09-25**|**PhD Forum: Efficient Privacy-Preserving Processing via Memory-Centric Computing**|Mpoki Mwaisela et.al.|[2409.16777](http://arxiv.org/abs/2409.16777)|null|\n", "2405.13938": "|**2024-05-22**|**eXmY: A Data Type and Technique for Arbitrary Bit Precision Quantization**|Aditya Agrawal et.al.|[2405.13938](http://arxiv.org/abs/2405.13938)|null|\n", "2404.11721": "|**2024-04-17**|**Functionality Locality, Mixture & Control = Logic = Memory**|Xiangjun Peng et.al.|[2404.11721](http://arxiv.org/abs/2404.11721)|null|\n", "2512.15988": "|**2025-12-17**|**Vertical NAND in a Ferroelectric-driven Paradigm Shift**|Giuk Kim et.al.|[2512.15988](http://arxiv.org/abs/2512.15988)|null|\n"}, "Cache Compression": {"2512.14946": "|**2025-12-16**|**EVICPRESS: Joint KV-Cache Compression and Eviction for Efficient LLM Serving**|Shaoting Feng et.al.|[2512.14946](http://arxiv.org/abs/2512.14946)|null|\n", "2512.12008": "|**2025-12-12**|**Hold Onto That Thought: Assessing KV Cache Compression On Reasoning**|Minghui Liu et.al.|[2512.12008](http://arxiv.org/abs/2512.12008)|null|\n", "2512.11920": "|**2025-12-11**|**CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving**|Dong Liu et.al.|[2512.11920](http://arxiv.org/abs/2512.11920)|null|\n", "2512.09238": "|**2025-12-10**|**Training-free Context-adaptive Attention for Efficient Long Context Modeling**|Zeng You et.al.|[2512.09238](http://arxiv.org/abs/2512.09238)|null|\n", "2512.06727": "|**2025-12-07**|**KV-CAR: KV Cache Compression using Autoencoders and KV Reuse in Large Language Models**|Sourjya Roy et.al.|[2512.06727](http://arxiv.org/abs/2512.06727)|null|\n", "2512.04857": "|**2025-12-04**|**Autoregressive Image Generation Needs Only a Few Lines of Cached Tokens**|Ziran Qin et.al.|[2512.04857](http://arxiv.org/abs/2512.04857)|null|\n", "2512.00504": "|**2025-11-29**|**G-KV: Decoding-Time KV Cache Eviction with Global Attention**|Mengqi Liao et.al.|[2512.00504](http://arxiv.org/abs/2512.00504)|null|\n", "2511.22481": "|**2025-11-27**|**OmniInfer: System-Wide Acceleration Techniques for Optimizing LLM Serving Throughput and Latency**|Jun Wang et.al.|[2511.22481](http://arxiv.org/abs/2511.22481)|null|\n", "2511.22118": "|**2025-11-27**|**Statistical Independence Aware Caching for LLM Workflows**|Yihan Dai et.al.|[2511.22118](http://arxiv.org/abs/2511.22118)|null|\n", "2511.18936": "|**2025-11-24**|**SWAN: Sparse Winnowed Attention for Reduced Inference Memory via Decompression-Free KV-Cache Compression**|Santhosh G S et.al.|[2511.18936](http://arxiv.org/abs/2511.18936)|null|\n", "2512.17917": "|**2025-12-01**|**KVReviver: Reversible KV Cache Compression with Sketch-Based Token Reconstruction**|Aomufei Yuan et.al.|[2512.17917](http://arxiv.org/abs/2512.17917)|null|\n", "2512.17914": "|**2025-11-27**|**Q-KVComm: Efficient Multi-Agent Communication Via Adaptive KV Cache Compression**|Boris Kriuk et.al.|[2512.17914](http://arxiv.org/abs/2512.17914)|null|\n"}, "Memory Bandwidth Optimization": {"2512.12949": "|**2025-12-15**|**FlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection**|Ziyu Huang et.al.|[2512.12949](http://arxiv.org/abs/2512.12949)|null|\n", "2512.11550": "|**2025-12-12**|**PD-Swap: Prefill-Decode Logic Swapping for End-to-End LLM Inference on Edge FPGAs via Dynamic Partial Reconfiguration**|Yifan Zhang et.al.|[2512.11550](http://arxiv.org/abs/2512.11550)|null|\n", "2512.11920": "|**2025-12-11**|**CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving**|Dong Liu et.al.|[2512.11920](http://arxiv.org/abs/2512.11920)|null|\n", "2512.08731": "|**2025-12-09**|**LaMoSys3.5D: Enabling 3.5D-IC-Based Large Language Model Inference Serving Systems via Hardware/Software Co-Design**|Qipan Wang et.al.|[2512.08731](http://arxiv.org/abs/2512.08731)|null|\n", "2512.08089": "|**2025-12-08**|**NysX: An Accurate and Energy-Efficient FPGA Accelerator for Hyperdimensional Graph Classification at the Edge**|Jebacyril Arockiaraj et.al.|[2512.08089](http://arxiv.org/abs/2512.08089)|null|\n", "2512.06443": "|**2025-12-06**|**Vec-LUT: Vector Table Lookup for Parallel Ultra-Low-Bit LLM Inference on Edge Devices**|Xiangyu Li et.al.|[2512.06443](http://arxiv.org/abs/2512.06443)|null|\n", "2512.06113": "|**2025-12-05**|**Hardware Software Optimizations for Fast Model Recovery on Reconfigurable Architectures**|Bin Xu et.al.|[2512.06113](http://arxiv.org/abs/2512.06113)|null|\n", "2512.03279": "|**2025-12-02**|**Getting the MOST out of your Storage Hierarchy with Mirror-Optimized Storage Tiering**|Kaiwei Tu et.al.|[2512.03279](http://arxiv.org/abs/2512.03279)|null|\n", "2512.01574": "|**2025-12-01**|**IVE: An Accelerator for Single-Server Private Information Retrieval Using Versatile Processing Elements**|Sangpyo Kim et.al.|[2512.01574](http://arxiv.org/abs/2512.01574)|null|\n", "2512.01278": "|**2025-12-01**|**Accelerating Large-Scale Reasoning Model Inference with Sparse Self-Speculative Decoding**|Yilong Zhao et.al.|[2512.01278](http://arxiv.org/abs/2512.01278)|null|\n", "2512.16056": "|**2025-12-18**|**MultiPath Transfer Engine: Breaking GPU and Host-Memory Bandwidth Bottlenecks in LLM Services**|Lingfeng Tang et.al.|[2512.16056](http://arxiv.org/abs/2512.16056)|null|\n", "2512.20814": "|**2025-12-23**|**FedMPDD: Communication-Efficient Federated Learning with Privacy Preservation Attributes via Projected Directional Derivative**|Mohammadreza Rostami et.al.|[2512.20814](http://arxiv.org/abs/2512.20814)|null|\n", "2512.19606": "|**2025-12-22**|**RAPID-LLM: Resilience-Aware Performance analysis of Infrastructure for Distributed LLM Training and Inference**|George Karfakis et.al.|[2512.19606](http://arxiv.org/abs/2512.19606)|null|\n", "2512.18345": "|**2025-12-20**|**Theodosian: A Deep Dive into Memory-Hierarchy-Centric FHE Acceleration**|Wonseok Choi et.al.|[2512.18345](http://arxiv.org/abs/2512.18345)|null|\n", "2512.17942": "|**2025-12-13**|**Fast Online Digital Twinning on FPGA for Mission Critical Applications**|Bin Xu et.al.|[2512.17942](http://arxiv.org/abs/2512.17942)|null|\n", "2512.22066": "|**2025-12-26**|**Prefill vs. Decode Bottlenecks: SRAM-Frequency Tradeoffs and the Memory-Bandwidth Ceiling**|Hannah Atmer et.al.|[2512.22066](http://arxiv.org/abs/2512.22066)|null|\n", "2512.21697": "|**2025-12-25**|**GaDE -- GPU-acceleration of time-dependent Dirac Equation for exascale**|Johanne Elise Vembe et.al.|[2512.21697](http://arxiv.org/abs/2512.21697)|null|\n"}, "Prefetching": {"2512.14151": "|**2025-12-16**|**Adaptive Cache Pollution Control for Large Language Model Inference Workloads Using Temporal CNN-Based Prediction and Priority-Aware Replacement**|Songze Liu et.al.|[2512.14151](http://arxiv.org/abs/2512.14151)|null|\n", "2512.12990": "|**2025-12-15**|**SliceMoE: Bit-Sliced Expert Caching under Miss-Rate Constraints for Efficient MoE Inference**|Yuseon Choi et.al.|[2512.12990](http://arxiv.org/abs/2512.12990)|null|\n", "2512.12036": "|**2025-12-12**|**Accelerating Sparse Matrix-Matrix Multiplication on GPUs with Processing Near HBMs**|Shiju Li et.al.|[2512.12036](http://arxiv.org/abs/2512.12036)|null|\n", "2512.11920": "|**2025-12-11**|**CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving**|Dong Liu et.al.|[2512.11920](http://arxiv.org/abs/2512.11920)|null|\n", "2512.09548": "|**2025-12-10**|**Supporting Dynamic Agentic Workloads: How Data and Agents Interact**|Ioana Giurgiu et.al.|[2512.09548](http://arxiv.org/abs/2512.09548)|null|\n", "2512.03972": "|**2025-12-03**|**OOPredictor: Predicting Object-Oriented Accesses using Static Analysis**|Hassan Arafat et.al.|[2512.03972](http://arxiv.org/abs/2512.03972)|null|\n", "2512.02513": "|**2025-12-03**|**Decentralized Fairness Aware Multi Task Federated Learning for VR Network**|Krishnendu S. Tharakan et.al.|[2512.02513](http://arxiv.org/abs/2512.02513)|null|\n", "2512.02300": "|**2025-12-02**|**DOLMA: A Data Object Level Memory Disaggregation Framework for HPC Applications**|Haoyu Zheng et.al.|[2512.02300](http://arxiv.org/abs/2512.02300)|null|\n", "2512.00722": "|**2025-11-30**|**SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs**|Jiaming Xu et.al.|[2512.00722](http://arxiv.org/abs/2512.00722)|null|\n", "2511.19973": "|**2025-11-25**|**Pickle Prefetcher: Programmable and Scalable Last-Level Cache Prefetcher**|Hoa Nguyen et.al.|[2511.19973](http://arxiv.org/abs/2511.19973)|null|\n"}, "Tiered Memory Management": {"2511.14043": "|**2025-11-18**|**AISAC: An Integrated multi-agent System for Transparent, Retrieval-Grounded Scientific Assistance**|Chandrachur Bhattacharya et.al.|[2511.14043](http://arxiv.org/abs/2511.14043)|null|\n", "2511.08568": "|**2025-11-11**|**Machine Learning-Guided Memory Optimization for DLRM Inference on Tiered Memory**|Jie Ren et.al.|[2511.08568](http://arxiv.org/abs/2511.08568)|null|\n", "2511.02371": "|**2025-11-04**|**LUMA-RAG: Lifelong Multimodal Agents with Provably Stable Streaming Alignment**|Rohan Wandre et.al.|[2511.02371](http://arxiv.org/abs/2511.02371)|null|\n", "2510.27288": "|**2025-10-31**|**Single femtosecond laser pulse-driven ferromagnetic switching**|Chen Xiao et.al.|[2510.27288](http://arxiv.org/abs/2510.27288)|null|\n", "2510.22869": "|**2025-10-26**|**Jenga: Responsive Tiered Memory Management without Thrashing**|Rohan Kadekodi et.al.|[2510.22869](http://arxiv.org/abs/2510.22869)|null|\n", "2511.07427": "|**2025-10-20**|**DynaKV: Enabling Accurate and Efficient Long-Sequence LLM Decoding on Smartphones**|Tuowei Wang et.al.|[2511.07427](http://arxiv.org/abs/2511.07427)|null|\n", "2510.15966": "|**2025-10-12**|**PISA: A Pragmatic Psych-Inspired Unified Memory System for Enhanced AI Agency**|Shian Jia et.al.|[2510.15966](http://arxiv.org/abs/2510.15966)|null|\n", "2509.25250": "|**2025-09-27**|**Memory Management and Contextual Consistency for Long-Running Low-Code Agents**|Jiexi Xu et.al.|[2509.25250](http://arxiv.org/abs/2509.25250)|null|\n", "2509.17388": "|**2025-10-24**|**Prefetching in Deep Memory Hierarchies with NVRAM as Main Memory**|Manel Lurbe et.al.|[2509.17388](http://arxiv.org/abs/2509.17388)|null|\n", "2507.01829": "|**2025-07-02**|**mGRADE: Minimal Recurrent Gating Meets Delay Convolutions for Lightweight Sequence Modeling**|Tristan Torchet et.al.|[2507.01829](http://arxiv.org/abs/2507.01829)|null|\n", "2512.20179": "|**2025-12-23**|**RESPOND: Risk-Enhanced Structured Pattern for LLM-driven Online Node-level Decision-making**|Dan Chen et.al.|[2512.20179](http://arxiv.org/abs/2512.20179)|null|\n", "2512.22624": "|**2025-12-27**|**Rethinking Memory Design in SAM-Based Visual Object Tracking**|Mohamad Alansari et.al.|[2512.22624](http://arxiv.org/abs/2512.22624)|null|\n"}, "Learning-based Memory Systems": {"2512.04540": "|**2025-12-16**|**VideoMem: Enhancing Ultra-Long Video Understanding via Adaptive Memory Management**|Hongbo Jin et.al.|[2512.04540](http://arxiv.org/abs/2512.04540)|null|\n", "2512.00722": "|**2025-11-30**|**SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs**|Jiaming Xu et.al.|[2512.00722](http://arxiv.org/abs/2512.00722)|null|\n", "2511.15963": "|**2025-11-26**|**PySERA: Open-Source Standardized Python Library for Automated, Scalable, and Reproducible Handcrafted and Deep Radiomics**|Mohammad R. Salmanpour et.al.|[2511.15963](http://arxiv.org/abs/2511.15963)|null|\n", "2509.06261": "|**2025-09-15**|**FineServe: Precision-Aware KV Slab and Two-Level Scheduling for Heterogeneous Precision LLM Serving**|Kyungmin Bin et.al.|[2509.06261](http://arxiv.org/abs/2509.06261)|null|\n", "2508.19828": "|**2025-10-08**|**Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning**|Sikuan Yan et.al.|[2508.19828](http://arxiv.org/abs/2508.19828)|null|\n", "2507.08548": "|**2025-07-11**|**SAM2RL: Towards Reinforcement Learning Memory Control in Segment Anything Model 2**|Alen Adamyan et.al.|[2507.08548](http://arxiv.org/abs/2507.08548)|null|\n", "2503.04392": "|**2025-07-08**|**AgentSafe: Safeguarding Large Language Model-based Multi-agent Systems via Hierarchical Data Management**|Junyuan Mao et.al.|[2503.04392](http://arxiv.org/abs/2503.04392)|null|\n", "2410.23537": "|**2024-10-31**|**ALISE: Accelerating Large Language Model Serving with Speculative Scheduling**|Youpeng Zhao et.al.|[2410.23537](http://arxiv.org/abs/2410.23537)|null|\n", "2406.08334": "|**2024-06-12**|**ProTrain: Efficient LLM Training via Memory-Aware Techniques**|Hanmei Yang et.al.|[2406.08334](http://arxiv.org/abs/2406.08334)|null|\n", "2206.10830": "|**2022-06-22**|**A Feature Memory Rearrangement Network for Visual Inspection of Textured Surface Defects Toward Edge Intelligent Manufacturing**|Haiming Yao et.al.|[2206.10830](http://arxiv.org/abs/2206.10830)|null|\n", "2512.20210": "|**2025-12-23**|**Predictive-LoRA: A Proactive and Fragmentation-Aware Serverless Inference System for LLMs**|Yinan Ni et.al.|[2512.20210](http://arxiv.org/abs/2512.20210)|null|\n"}, "Memory Protection & Security": {"2511.10633": "|**2025-11-13**|**Impacts of Decoder Latency on Utility-Scale Quantum Computer Architectures**|Abdullah Khalid et.al.|[2511.10633](http://arxiv.org/abs/2511.10633)|null|\n", "2511.09410": "|**2025-11-12**|**No Cords Attached: Coordination-Free Concurrent Lock-Free Queues**|Yusuf Motiwala et.al.|[2511.09410](http://arxiv.org/abs/2511.09410)|null|\n", "2510.27070": "|**2025-11-10**|**Descriptor-Based Object-Aware Memory Systems: A Comprehensive Review**|Dong Tong et.al.|[2510.27070](http://arxiv.org/abs/2510.27070)|null|\n", "2510.22566": "|**2025-10-26**|**FAARM: Firmware Attestation and Authentication Framework for Mali GPUs**|Md. Mehedi Hasan et.al.|[2510.22566](http://arxiv.org/abs/2510.22566)|null|\n", "2510.11505": "|**2025-10-13**|**Knowledge-Guided Machine Learning Models to Upscale Evapotranspiration in the U.S. Midwest**|Aleksei Rozanov et.al.|[2510.11505](http://arxiv.org/abs/2510.11505)|null|\n", "2510.02373": "|**2025-09-29**|**A-MemGuard: A Proactive Defense Framework for LLM-Based Agent Memory**|Qianshan Wei et.al.|[2510.02373](http://arxiv.org/abs/2510.02373)|null|\n", "2509.05129": "|**2025-09-05**|**Efficient Exact Resistance Distance Computation on Small-Treewidth Graphs: a Labelling Approach**|Meihao Liao et.al.|[2509.05129](http://arxiv.org/abs/2509.05129)|null|\n", "2508.03879": "|**2025-08-05**|**RX-INT: A Kernel Engine for Real-Time Detection and Analysis of In-Memory Threats**|Arjun Juneja et.al.|[2508.03879](http://arxiv.org/abs/2508.03879)|null|\n", "2507.13142": "|**2025-09-26**|**From Roots to Rewards: Dynamic Tree Reasoning with Reinforcement Learning**|Ahmed Bahloul et.al.|[2507.13142](http://arxiv.org/abs/2507.13142)|null|\n", "2507.04818": "|**2025-07-07**|**Enabling Security on the Edge: A CHERI Compartmentalized Network Stack**|Donato Ferraro et.al.|[2507.04818](http://arxiv.org/abs/2507.04818)|null|\n", "2512.16047": "|**2025-12-18**|**Silicon T centre hyperfine structure and memory protection schemes**|Nicholas Brunelle et.al.|[2512.16047](http://arxiv.org/abs/2512.16047)|null|\n"}, "Oblivious Memory Systems": {"2512.12006": "|**2025-12-27**|**MVP-ORAM: a Wait-free Concurrent ORAM for Confidential BFT Storage**|Robin Vassantlal et.al.|[2512.12006](http://arxiv.org/abs/2512.12006)|null|\n", "2511.07123": "|**2025-11-27**|**Harnessing Sparsification in Federated Learning: A Secure, Efficient, and Differentially Private Realization**|Shuangqing Xu et.al.|[2511.07123](http://arxiv.org/abs/2511.07123)|null|\n", "2510.22566": "|**2025-10-26**|**FAARM: Firmware Attestation and Authentication Framework for Mali GPUs**|Md. Mehedi Hasan et.al.|[2510.22566](http://arxiv.org/abs/2510.22566)|null|\n", "2509.18909": "|**2025-09-23**|**Obelix: Mitigating Side-Channels Through Dynamic Obfuscation**|Jan Wichelmann et.al.|[2509.18909](http://arxiv.org/abs/2509.18909)|null|\n", "2508.18081": "|**2025-08-25**|**GWTC-4.0: Methods for Identifying and Characterizing Gravitational-wave Transients**|The LIGO Scientific Collaboration et.al.|[2508.18081](http://arxiv.org/abs/2508.18081)|null|\n", "2508.18080": "|**2025-09-23**|**GWTC-4.0: An Introduction to Version 4.0 of the Gravitational-Wave Transient Catalog**|The LIGO Scientific Collaboration et.al.|[2508.18080](http://arxiv.org/abs/2508.18080)|null|\n", "2507.23247": "|**2025-11-07**|**P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication**|Sneha Oram et.al.|[2507.23247](http://arxiv.org/abs/2507.23247)|null|\n", "2506.15924": "|**2025-12-11**|**SNPeek: Side-Channel Analysis for Privacy Applications on Confidential VMs**|Ruiyi Zhang et.al.|[2506.15924](http://arxiv.org/abs/2506.15924)|null|\n", "2506.17318": "|**2025-06-18**|**Context manipulation attacks : Web agents are susceptible to corrupted memory**|Atharv Singh Patlan et.al.|[2506.17318](http://arxiv.org/abs/2506.17318)|null|\n", "2506.07034": "|**2025-06-08**|**NanoZone: Scalable, Efficient, and Secure Memory Protection for Arm CCA**|Shiqi Liu et.al.|[2506.07034](http://arxiv.org/abs/2506.07034)|null|\n"}, "Vector & ISA Extensions": {"2510.07843": "|**2025-10-09**|**Accelerating vRAN and O-RAN with SIMD: Architectural Perspectives and Performance Evaluation**|Jaebum Park et.al.|[2510.07843](http://arxiv.org/abs/2510.07843)|null|\n", "2510.06834": "|**2025-10-08**|**Vectorized FlashAttention with Low-cost Exponential Computation in RISC-V Vector Processors**|Vasileios Titopoulos et.al.|[2510.06834](http://arxiv.org/abs/2510.06834)|null|\n", "2507.03522": "|**2025-07-04**|**A Flexible Instruction Set Architecture for Efficient GEMMs**|Alexandre de Limas Santana et.al.|[2507.03522](http://arxiv.org/abs/2507.03522)|null|\n", "2505.18231": "|**2025-12-14**|**NSNQuant: A Double Normalization Approach for Calibration-Free Low-Bit Vector Quantization of KV Cache**|Donghyun Son et.al.|[2505.18231](http://arxiv.org/abs/2505.18231)|null|\n", "2505.13544": "|**2025-11-02**|**Multi-head Temporal Latent Attention**|Keqi Deng et.al.|[2505.13544](http://arxiv.org/abs/2505.13544)|null|\n", "2504.10345": "|**2025-04-14**|**AraOS: Analyzing the Impact of Virtual Memory Management on Vector Unit Performance**|Matteo Perotti et.al.|[2504.10345](http://arxiv.org/abs/2504.10345)|null|\n", "2503.17333": "|**2025-03-24**|**Register Dispersion: Reducing the Footprint of the Vector Register File in Vector Engines of Low-Cost RISC-V CPUs**|Vasileios Titopoulos et.al.|[2503.17333](http://arxiv.org/abs/2503.17333)|null|\n", "2501.19392": "|**2025-02-28**|**Cache Me If You Must: Adaptive Key-Value Quantization for Large Language Models**|Alina Shutova et.al.|[2501.19392](http://arxiv.org/abs/2501.19392)|null|\n", "2501.16588": "|**2025-01-28**|**Fine-Tuned Language Models as Space Systems Controllers**|Enrico M. Zucchelli et.al.|[2501.16588](http://arxiv.org/abs/2501.16588)|null|\n", "2501.09902": "|**2025-01-17**|**Multi-Dimensional Vector ISA Extension for Mobile In-Cache Computing**|Alireza Khadem et.al.|[2501.09902](http://arxiv.org/abs/2501.09902)|null|\n"}, "CXL & Disaggregated Memory": {"2512.12949": "|**2025-12-15**|**FlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection**|Ziyu Huang et.al.|[2512.12949](http://arxiv.org/abs/2512.12949)|null|\n", "2512.11920": "|**2025-12-11**|**CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving**|Dong Liu et.al.|[2512.11920](http://arxiv.org/abs/2512.11920)|null|\n", "2512.08005": "|**2025-12-08**|**Modeling the Potential of Message-Free Communication via CXL.mem**|Stepan Vanecek et.al.|[2512.08005](http://arxiv.org/abs/2512.08005)|null|\n", "2512.04476": "|**2025-12-04**|**Context-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems**|Zehao Fan et.al.|[2512.04476](http://arxiv.org/abs/2512.04476)|null|\n", "2512.04449": "|**2025-12-04**|**Offloading to CXL-based Computational Memory**|Suyeon Lee et.al.|[2512.04449](http://arxiv.org/abs/2512.04449)|null|\n", "2512.02300": "|**2025-12-02**|**DOLMA: A Data Object Level Memory Disaggregation Framework for HPC Applications**|Haoyu Zheng et.al.|[2512.02300](http://arxiv.org/abs/2512.02300)|null|\n", "2512.01357": "|**2025-12-01**|**Tangram: Accelerating Serverless LLM Loading through GPU Memory Reuse and Affinity**|Wenbin Zhu et.al.|[2512.01357](http://arxiv.org/abs/2512.01357)|null|\n", "2511.23011": "|**2025-11-28**|**Cohet: A CXL-Driven Coherent Heterogeneous Computing Framework with Hardware-Calibrated Full-System Simulation**|Yanjing Wang et.al.|[2511.23011](http://arxiv.org/abs/2511.23011)|null|\n", "2511.20172": "|**2025-11-27**|**Beluga: A CXL-Based Memory Architecture for Scalable and Efficient LLM KVCache Management**|Xinjun Yang et.al.|[2511.20172](http://arxiv.org/abs/2511.20172)|null|\n", "2511.15015": "|**2025-11-24**|**Dynamic Expert Quantization for Scalable Mixture-of-Experts Inference**|Kexin Chu et.al.|[2511.15015](http://arxiv.org/abs/2511.15015)|null|\n", "2512.16148": "|**2025-12-18**|**FlexKV: Flexible Index Offloading for Memory-Disaggregated Key-Value Store**|Zhisheng Hu et.al.|[2512.16148](http://arxiv.org/abs/2512.16148)|null|\n", "2512.16136": "|**2025-12-18**|**Lotus: Optimizing Disaggregated Transactions with Disaggregated Locks**|Zhisheng Hu et.al.|[2512.16136](http://arxiv.org/abs/2512.16136)|null|\n", "2512.18194": "|**2025-12-20**|**TraCT: Disaggregated LLM Serving with CXL Shared Memory KV Cache at Rack-Scale**|Dongha Yoon et.al.|[2512.18194](http://arxiv.org/abs/2512.18194)|null|\n", "2512.22995": "|**2025-12-28**|**Evolution of Buffer Management in Database Systems: From Classical Algorithms to Machine Learning and Disaggregated Memory**|Prudhvi Gadupudi et.al.|[2512.22995](http://arxiv.org/abs/2512.22995)|null|\n", "2512.22215": "|**2025-12-22**|**SPUMA: a minimally invasive approach to the GPU porting of OPENFOAM**|Simone Bn\u00e0 et.al.|[2512.22215](http://arxiv.org/abs/2512.22215)|null|\n"}, "NUMA & Heterogeneous Memory": {"2512.12295": "|**2025-12-17**|**Near-Zero-Overhead Freshness for Recommendation Systems via Inference-Side Model Updates**|Wenjun Yu et.al.|[2512.12295](http://arxiv.org/abs/2512.12295)|null|\n", "2512.08005": "|**2025-12-08**|**Modeling the Potential of Message-Free Communication via CXL.mem**|Stepan Vanecek et.al.|[2512.08005](http://arxiv.org/abs/2512.08005)|null|\n", "2512.06806": "|**2025-12-07**|**METRION: A Framework for Accurate Software Energy Measurement**|Benjamin Weigell et.al.|[2512.06806](http://arxiv.org/abs/2512.06806)|null|\n", "2512.01646": "|**2025-12-09**|**StarDist: A Code Generator for Distributed Graph Algorithms**|Barenya Kumar Nandy et.al.|[2512.01646](http://arxiv.org/abs/2512.01646)|null|\n", "2512.01574": "|**2025-12-01**|**IVE: An Accelerator for Single-Server Private Information Retrieval Using Versatile Processing Elements**|Sangpyo Kim et.al.|[2512.01574](http://arxiv.org/abs/2512.01574)|null|\n", "2511.21535": "|**2025-11-26**|**Modeling the Effect of Data Redundancy on Speedup in MLFMA Near-Field Computation**|Morteza Sadeghi et.al.|[2511.21535](http://arxiv.org/abs/2511.21535)|null|\n", "2511.20834": "|**2025-11-25**|**Accelerating Sparse Convolutions in Voxel-Based Point Cloud Networks**|Dionysios Adamopoulos et.al.|[2511.20834](http://arxiv.org/abs/2511.20834)|null|\n", "2511.19832": "|**2025-11-25**|**Enabling Scientific Workflow Scheduling Research in Non-Uniform Memory Access Architectures**|Aurelio Vivas et.al.|[2511.19832](http://arxiv.org/abs/2511.19832)|null|\n", "2511.14852": "|**2025-11-18**|**PolyKAN: Efficient Fused GPU Operators for Polynomial Kolmogorov-Arnold Network Variants**|Mingkun Yu et.al.|[2511.14852](http://arxiv.org/abs/2511.14852)|null|\n", "2511.13410": "|**2025-11-26**|**Mem-PAL: Towards Memory-based Personalized Dialogue Assistants for Long-term User-Agent Interaction**|Zhaopei Huang et.al.|[2511.13410](http://arxiv.org/abs/2511.13410)|null|\n", "2512.22995": "|**2025-12-28**|**Evolution of Buffer Management in Database Systems: From Classical Algorithms to Machine Learning and Disaggregated Memory**|Prudhvi Gadupudi et.al.|[2512.22995](http://arxiv.org/abs/2512.22995)|null|\n", "2512.21931": "|**2025-12-26**|**Multipolar fluctuations from localized 4f electrons in CeRh2As2**|Koki Numa et.al.|[2512.21931](http://arxiv.org/abs/2512.21931)|null|\n"}, "GPU Memory Systems": {"2512.14946": "|**2025-12-16**|**EVICPRESS: Joint KV-Cache Compression and Eviction for Efficient LLM Serving**|Shaoting Feng et.al.|[2512.14946](http://arxiv.org/abs/2512.14946)|null|\n", "2512.14540": "|**2025-12-16**|**CAPRMIL: Context-Aware Patch Representations for Multiple Instance Learning**|Andreas Lolos et.al.|[2512.14540](http://arxiv.org/abs/2512.14540)|null|\n", "2512.14481": "|**2025-12-16**|**SASQ: Static Activation Scaling for Quantization-Aware Training in Large Language Models**|Shizhuo Mao et.al.|[2512.14481](http://arxiv.org/abs/2512.14481)|null|\n", "2512.13921": "|**2025-12-15**|**Sliding Window Recurrences for Sequence Models**|Dragos Secrieru et.al.|[2512.13921](http://arxiv.org/abs/2512.13921)|null|\n", "2512.12560": "|**2025-12-14**|**StreamingAssistant: Efficient Visual Token Pruning for Accelerating Online Video Understanding**|Xinqi Jin et.al.|[2512.12560](http://arxiv.org/abs/2512.12560)|null|\n", "2512.12357": "|**2025-12-13**|**TCLeaf-Net: a transformer-convolution framework with global-local attention for robust in-field lesion-level plant leaf disease detection**|Zishen Song et.al.|[2512.12357](http://arxiv.org/abs/2512.12357)|null|\n", "2512.12036": "|**2025-12-12**|**Accelerating Sparse Matrix-Matrix Multiplication on GPUs with Processing Near HBMs**|Shiju Li et.al.|[2512.12036](http://arxiv.org/abs/2512.12036)|null|\n", "2512.11920": "|**2025-12-11**|**CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving**|Dong Liu et.al.|[2512.11920](http://arxiv.org/abs/2512.11920)|null|\n", "2512.10576": "|**2025-12-11**|**ESS: An Offload-Centric Latent-Cache Management Architecture for DeepSeek-V3.2-Exp**|Xinhang Chen et.al.|[2512.10576](http://arxiv.org/abs/2512.10576)|null|\n", "2512.09472": "|**2025-12-10**|**WarmServe: Enabling One-for-Many GPU Prewarming for Multi-LLM Serving**|Chiheng Lou et.al.|[2512.09472](http://arxiv.org/abs/2512.09472)|null|\n", "2512.16822": "|**2025-12-18**|**MEPIC: Memory Efficient Position Independent Caching for LLM Serving**|Qian Wang et.al.|[2512.16822](http://arxiv.org/abs/2512.16822)|null|\n", "2512.15764": "|**2025-12-12**|**AdaGradSelect: An adaptive gradient-guided layer selection method for efficient fine-tuning of SLMs**|Anshul Kumar et.al.|[2512.15764](http://arxiv.org/abs/2512.15764)|null|\n", "2512.21333": "|**2025-12-24**|**Fast SAM2 with Text-Driven Token Pruning**|Avilasha Mandal et.al.|[2512.21333](http://arxiv.org/abs/2512.21333)|null|\n", "2512.21133": "|**2025-12-24**|**SparScene: Efficient Traffic Scene Representation via Sparse Graph Learning for Large-Scale Trajectory Generation**|Xiaoyu Mo et.al.|[2512.21133](http://arxiv.org/abs/2512.21133)|null|\n", "2512.20920": "|**2025-12-24**|**RevFFN: Memory-Efficient Full-Parameter Fine-Tuning of Mixture-of-Experts LLMs with Reversible Blocks**|Ningyuan Liu et.al.|[2512.20920](http://arxiv.org/abs/2512.20920)|null|\n", "2512.20210": "|**2025-12-23**|**Predictive-LoRA: A Proactive and Fragmentation-Aware Serverless Inference System for LLMs**|Yinan Ni et.al.|[2512.20210](http://arxiv.org/abs/2512.20210)|null|\n", "2512.19606": "|**2025-12-22**|**RAPID-LLM: Resilience-Aware Performance analysis of Infrastructure for Distributed LLM Training and Inference**|George Karfakis et.al.|[2512.19606](http://arxiv.org/abs/2512.19606)|null|\n", "2512.18152": "|**2025-12-20**|**Making Strong Error-Correcting Codes Work Effectively for HBM in AI Inference**|Rui Xie et.al.|[2512.18152](http://arxiv.org/abs/2512.18152)|null|\n", "2512.17279": "|**2025-12-19**|**Diagnostic Performance of Universal-Learning Ultrasound AI Across Multiple Organs and Tasks: the UUSIC25 Challenge**|Zehui Lin et.al.|[2512.17279](http://arxiv.org/abs/2512.17279)|null|\n", "2512.17229": "|**2025-12-19**|**Video Detective: Seek Critical Clues Recurrently to Answer Question from Long Videos**|Henghui Du et.al.|[2512.17229](http://arxiv.org/abs/2512.17229)|null|\n", "2512.17073": "|**2025-12-18**|**Bandwidth-Efficient Adaptive Mixture-of-Experts via Low-Rank Compensation**|Zhenyu Liu et.al.|[2512.17073](http://arxiv.org/abs/2512.17073)|null|\n", "2512.23065": "|**2025-12-28**|**TabiBERT: A Large-Scale ModernBERT Foundation Model and Unified Benchmarking Framework for Turkish**|Melik\u015fah T\u00fcrker et.al.|[2512.23065](http://arxiv.org/abs/2512.23065)|null|\n", "2512.21884": "|**2025-12-26**|**Optimizing Resource Allocation for Geographically-Distributed Inference by Large Language Models**|Tingyang Sun et.al.|[2512.21884](http://arxiv.org/abs/2512.21884)|null|\n", "2512.21881": "|**2025-12-26**|**SLIM-Brain: A Data- and Training-Efficient Foundation Model for fMRI Data Analysis**|Mo Wang et.al.|[2512.21881](http://arxiv.org/abs/2512.21881)|null|\n", "2512.22195": "|**2025-12-20**|**MatKV: Trading Compute for Flash Storage in LLM Inference**|Kun-Woo Shin et.al.|[2512.22195](http://arxiv.org/abs/2512.22195)|null|\n"}, "RDMA": {"2512.11094": "|**2025-12-11**|**SHIFT: An RDMA Failure-Resilient Layer for Distributed Training**|Shengkai Lin et.al.|[2512.11094](http://arxiv.org/abs/2512.11094)|null|\n", "2512.02862": "|**2025-12-02**|**PystachIO: Efficient Distributed GPU Query Processing with PyTorch over Fast Networks & Fast Storage**|Jigao Luo et.al.|[2512.02862](http://arxiv.org/abs/2512.02862)|null|\n", "2512.02546": "|**2025-12-02**|**Solutions for Distributed Memory Access Mechanism on HPC Clusters**|Jan Meizner et.al.|[2512.02546](http://arxiv.org/abs/2512.02546)|null|\n", "2512.02480": "|**2025-12-02**|**How IFRS Affects Value Relevance and Key Financial Indicators? Evidence from the UK**|Yhlas Sovbetov et.al.|[2512.02480](http://arxiv.org/abs/2512.02480)|null|\n", "2511.22880": "|**2025-11-28**|**Serving Heterogeneous LoRA Adapters in Distributed LLM Inference Systems**|Shashwat Jaiswal et.al.|[2511.22880](http://arxiv.org/abs/2511.22880)|null|\n", "2511.21018": "|**2025-11-26**|**Handling of Memory Page Faults during Virtual-Address RDMA**|Antonis Psistakis et.al.|[2511.21018](http://arxiv.org/abs/2511.21018)|null|\n", "2511.20172": "|**2025-11-27**|**Beluga: A CXL-Based Memory Architecture for Scalable and Efficient LLM KVCache Management**|Xinjun Yang et.al.|[2511.20172](http://arxiv.org/abs/2511.20172)|null|\n", "2511.19827": "|**2025-11-25**|**ReDirector: Creating Any-Length Video Retakes with Rotary Camera Encoding**|Byeongjun Park et.al.|[2511.19827](http://arxiv.org/abs/2511.19827)|null|\n", "2511.15076": "|**2025-11-24**|**GPU-Initiated Networking for NCCL**|Khaled Hamidouche et.al.|[2511.15076](http://arxiv.org/abs/2511.15076)|null|\n", "2511.09557": "|**2025-12-15**|**LLM Inference Beyond a Single Node: From Bottlenecks to Mitigations with Fast All-Reduce Communication**|Prajwal Singhania et.al.|[2511.09557](http://arxiv.org/abs/2511.09557)|null|\n", "2512.16136": "|**2025-12-18**|**Lotus: Optimizing Disaggregated Transactions with Disaggregated Locks**|Zhisheng Hu et.al.|[2512.16136](http://arxiv.org/abs/2512.16136)|null|\n", "2512.19849": "|**2025-12-22**|**UCCL-EP: Portable Expert-Parallel Communication**|Ziming Mao et.al.|[2512.19849](http://arxiv.org/abs/2512.19849)|null|\n", "2512.18194": "|**2025-12-20**|**TraCT: Disaggregated LLM Serving with CXL Shared Memory KV Cache at Rack-Scale**|Dongha Yoon et.al.|[2512.18194](http://arxiv.org/abs/2512.18194)|null|\n", "2512.22995": "|**2025-12-28**|**Evolution of Buffer Management in Database Systems: From Classical Algorithms to Machine Learning and Disaggregated Memory**|Prudhvi Gadupudi et.al.|[2512.22995](http://arxiv.org/abs/2512.22995)|null|\n", "2512.22743": "|**2025-12-28**|**OptiNIC: A Resilient and Tail-Optimal RDMA NIC for Distributed ML Workloads**|Ertza Warraich et.al.|[2512.22743](http://arxiv.org/abs/2512.22743)|null|\n"}, "Disaggregated Memory": {"2512.18194": "|**2025-12-20**|**TraCT: Disaggregated LLM Serving with CXL Shared Memory KV Cache at Rack-Scale**|Dongha Yoon et.al.|[2512.18194](http://arxiv.org/abs/2512.18194)|null|\n", "2512.16148": "|**2025-12-18**|**FlexKV: Flexible Index Offloading for Memory-Disaggregated Key-Value Store**|Zhisheng Hu et.al.|[2512.16148](http://arxiv.org/abs/2512.16148)|null|\n", "2512.16136": "|**2025-12-18**|**Lotus: Optimizing Disaggregated Transactions with Disaggregated Locks**|Zhisheng Hu et.al.|[2512.16136](http://arxiv.org/abs/2512.16136)|null|\n", "2512.12949": "|**2025-12-15**|**FlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection**|Ziyu Huang et.al.|[2512.12949](http://arxiv.org/abs/2512.12949)|null|\n", "2512.12295": "|**2025-12-17**|**Near-Zero-Overhead Freshness for Recommendation Systems via Inference-Side Model Updates**|Wenjun Yu et.al.|[2512.12295](http://arxiv.org/abs/2512.12295)|null|\n", "2512.11920": "|**2025-12-11**|**CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving**|Dong Liu et.al.|[2512.11920](http://arxiv.org/abs/2512.11920)|null|\n", "2512.08005": "|**2025-12-08**|**Modeling the Potential of Message-Free Communication via CXL.mem**|Stepan Vanecek et.al.|[2512.08005](http://arxiv.org/abs/2512.08005)|null|\n", "2512.04476": "|**2025-12-04**|**Context-Aware Mixture-of-Experts Inference on CXL-Enabled GPU-NDP Systems**|Zehao Fan et.al.|[2512.04476](http://arxiv.org/abs/2512.04476)|null|\n", "2512.04449": "|**2025-12-04**|**Offloading to CXL-based Computational Memory**|Suyeon Lee et.al.|[2512.04449](http://arxiv.org/abs/2512.04449)|null|\n", "2512.02300": "|**2025-12-02**|**DOLMA: A Data Object Level Memory Disaggregation Framework for HPC Applications**|Haoyu Zheng et.al.|[2512.02300](http://arxiv.org/abs/2512.02300)|null|\n", "2512.22995": "|**2025-12-28**|**Evolution of Buffer Management in Database Systems: From Classical Algorithms to Machine Learning and Disaggregated Memory**|Prudhvi Gadupudi et.al.|[2512.22995](http://arxiv.org/abs/2512.22995)|null|\n", "2512.21931": "|**2025-12-26**|**Multipolar fluctuations from localized 4f electrons in CeRh2As2**|Koki Numa et.al.|[2512.21931](http://arxiv.org/abs/2512.21931)|null|\n", "2512.22215": "|**2025-12-22**|**SPUMA: a minimally invasive approach to the GPU porting of OPENFOAM**|Simone Bn\u00e0 et.al.|[2512.22215](http://arxiv.org/abs/2512.22215)|null|\n"}}